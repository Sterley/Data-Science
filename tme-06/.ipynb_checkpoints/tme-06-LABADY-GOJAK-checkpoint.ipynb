{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IA & Data science (LU3IN0226) -- 2021-2022\n",
    "--------\n",
    "*&copy; Equipe pédagogique: Vincent Guigue, Christophe Marsala, Olivier Schwander.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TD-TME 6: les arbres de décision (catégoriel)\n",
    "\n",
    "L'objectif de ce notebook est d'implémenter un algorithme d'apprentissage supervisé qui travaille sur des données catégorielles, l'algorithme de construction d'arbres de décision vu en cours.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"RED\"><b>[Q]</b></font> **Indiquer dans la boîte ci-dessous vos noms et prénoms :**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*LABADY Sterley Gilbert - GOJAK Zlatan*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\"><b>[Q]</b></font> **Renommer ce fichier ipython**\n",
    "\n",
    "Tout en haut de cette page, cliquer sur <tt>tme-06</tt> et rajouter à la suite de <tt>tme-06</tt> les noms des membres du binômes séparés par un tiret.\n",
    "\n",
    "<font color=\"RED\" size=\"+1\">IMPORTANT: soumission de votre fichier final</font>\n",
    "\n",
    "**Nom à donner au fichier à poster** : *tme-06-Nom1_Nom2.ipynb* \n",
    "- *Nom1* et *Nom2* : noms des membres du binôme\n",
    "- ne pas compresser ou faire une archive: il faut rendre le fichier ipython tel quel, éventuellement, si vous avez d'autres fichiers vous les rendez séparément.\n",
    "\n",
    "**Echancier pour la soumission de votre compte-rendu:**\n",
    "- le compte-rendu d'une séance doit être remis obligatoirement <font color=\"RED\">avant la séance suivante</font>.\n",
    "\n",
    "**Le compte-rendu est soumis sur la page Moodle.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bilan des séances précédentes\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "Avant de vous attaquer à la partie suivante sur la visualisation des données, vous devez avoir terminé les TME précédents.\n",
    "Si vous ne les avez pas terminées : consacrer le début de ce TME à vous mettre à jour.    \n",
    "</div>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des librairies standards:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "# Importation de votre librairie iads:\n",
    "# La ligne suivante permet de préciser le chemin d'accès à la librairie iads\n",
    "import sys\n",
    "sys.path.append('../')   # iads doit être dans le répertoire frère du répertoire courant !\n",
    "\n",
    "# Importation de la librairie iads\n",
    "import iads as iads\n",
    "\n",
    "# importation de Classifiers\n",
    "from iads import Classifiers as cl\n",
    "\n",
    "# importation de utils\n",
    "from iads import utils as ut\n",
    "\n",
    "# commande TRES utile pour recharger automatiquement le code que vous modifiez dans les modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin de réaliser les premiers essais avec les fonctions que l'on va programmer, on charge la base sur les élections vue dans le cours 6 et que l'on a utilisé dans le notebook précédent (cf. le notebook précédent pour revoir les étapes qui suivent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adresse</th>\n",
       "      <th>Majeur?</th>\n",
       "      <th>Nationalite</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Paris</td>\n",
       "      <td>oui</td>\n",
       "      <td>Francais</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paris</td>\n",
       "      <td>non</td>\n",
       "      <td>Francais</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Montpellier</td>\n",
       "      <td>oui</td>\n",
       "      <td>Italien</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Paris</td>\n",
       "      <td>oui</td>\n",
       "      <td>Suisse</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Strasbourg</td>\n",
       "      <td>non</td>\n",
       "      <td>Italien</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Strasbourg</td>\n",
       "      <td>non</td>\n",
       "      <td>Francais</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Strasbourg</td>\n",
       "      <td>oui</td>\n",
       "      <td>Francais</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Montpellier</td>\n",
       "      <td>oui</td>\n",
       "      <td>Suisse</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Adresse Majeur? Nationalite  Label\n",
       "0        Paris     oui    Francais      1\n",
       "1        Paris     non    Francais     -1\n",
       "2  Montpellier     oui     Italien      1\n",
       "3        Paris     oui      Suisse     -1\n",
       "4   Strasbourg     non     Italien     -1\n",
       "5   Strasbourg     non    Francais     -1\n",
       "6   Strasbourg     oui    Francais      1\n",
       "7  Montpellier     oui      Suisse     -1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chargement des fichiers de données :\n",
    "\n",
    "elections_df = pd.read_csv(\"data/elections.csv\")\n",
    "elections_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Adresse', 'Majeur?', 'Nationalite', 'Label'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pour avoir le nom des colonnes de ce dataframe :\n",
    "elections_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour ne garder que le nom des variables de description (et pas la classe):\n",
    "# sous la forme d'une liste:\n",
    "\n",
    "elections_noms = [nom for nom in elections_df.columns if nom != 'Label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noms des features:  ['Adresse', 'Majeur?', 'Nationalite']\n"
     ]
    }
   ],
   "source": [
    "# Passer du dataframe à des arrays:\n",
    "elections_desc = np.array(elections_df[elections_noms])\n",
    "elections_label = np.array(elections_df['Label'])\n",
    "\n",
    "print(\"Noms des features: \",elections_noms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, -1, -1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elections_label[elections_desc[:,0] == \"Paris\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Premières fonctions: entropie et classe majoritaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Ecrire la fonction <code>classe_majoritaire</code> qui, étant donné un array de labels rend la classe majoritaire (celle qui est possédée par le plus grand nombre d'exemples donc...). En cas d'égalité, cette fonction rend la première classe rencontrée.\n",
    "\n",
    "**Remarque :** on utilise la fonction numpy `unique` qui permet d'obtenir les valeurs différentes d'un array ainsi que leur décompte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valeurs différentes dans l'array           :  [-1  1]\n",
      "Décompte de chaque valeur (respectivement) :  [5 3]\n"
     ]
    }
   ],
   "source": [
    "# Exemple d'utilisation de la fonction numpy `unique`\n",
    "\n",
    "valeurs, nb_fois = np.unique(elections_label,return_counts=True)\n",
    "\n",
    "print(\"Valeurs différentes dans l'array           : \",valeurs)\n",
    "print(\"Décompte de chaque valeur (respectivement) : \",nb_fois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classe_majoritaire(Y):\n",
    "    valeurs, nb_fois = np.unique(Y,return_counts=True)\n",
    "    return valeurs[np.argmax(nb_fois)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vérification sur nos données:\n",
    "classe_majoritaire(elections_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropie et gain d'information\n",
    "\n",
    "Pour sélectionner les attributs lors de la construction de l'arbre de décision, on utilise une mesure de gain d'information basée sur une entropie, comme cela a été présenté en cours.    \n",
    "   \n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "On note $\\{c_1, c_2,..., c_k\\}$, l'ensemble des valeurs de classes possibles dans un ensemble $Y$.\n",
    "\n",
    "On note $p_1$ la probabilité de la classe $c_1$ parmi $Y$, etc., et on note $P=(p_1, p_2,..., p_k)$ la distribution de probabilités sur les classes.\n",
    "\n",
    "L'**entropie de Shannon** de la distribution $P$ est donnée par:\n",
    "\n",
    "$ H_S(P) = -\\sum_{i=1}^{k} p_i \\log_k(p_i)$\n",
    "\n",
    "Le logarithme utilisé est le logarithme en base $k$ afin d'obtenir une valeur comprise entre $0$ et $1$ de l'entropie. \n",
    "\n",
    "</div>\n",
    "    \n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "Remarque: pour nous, une *distribution de probabilités* est donc représentée par une **liste** $P=[p_1,...,p_k]$ de valeurs réelles telle que\n",
    "* pour tout $i=1,..., k$ : $0 \\leq p_i \\leq 1$\n",
    "* $\\sum_{i=1}^{k}p_i = 1$\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\"><b>[Q]</b></font> Ecrire la fonction `shannon` qui, étant donné une distribution de probabilités $P$ fournie sous la forme d'une liste de nombres, rend la valeur de $H_S(P)$, l'entropie de Shannon de $P$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def shannon(P):\n",
    "    \"\"\" list[Number] -> float\n",
    "        Hypothèse: la somme des nombres de P vaut 1\n",
    "        P correspond à une distribution de probabilité\n",
    "        rend la valeur de l'entropie de Shannon correspondante\n",
    "    \"\"\"\n",
    "    if (len(P)==0 or len(P)==1):\n",
    "        return 0.0\n",
    "    somme=0\n",
    "    for p in P:\n",
    "        if p != 0:\n",
    "            somme+= p*math.log(p,len(P))\n",
    "    return - somme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H([1]) =  0.0\n",
      "H([1,0]) =  -0.0\n",
      "H([0.25, 0.25, 0.25, 0.25]) =  1.0\n",
      "H([0.7, 0.1, 0.2, 0.0]) =  0.5783898247235197\n",
      "H([1.0/3, 2.0/3]) =  0.9182958340544896\n"
     ]
    }
   ],
   "source": [
    "# Exemples d'utilisation:\n",
    "print(\"H([1]) = \", shannon([1]))\n",
    "print(\"H([1,0]) = \", shannon([1, 0]))\n",
    "print(\"H([0.25, 0.25, 0.25, 0.25]) = \", shannon([0.25, 0.25, 0.25, 0.25]))\n",
    "print(\"H([0.7, 0.1, 0.2, 0.0]) = \", shannon([0.7, 0.1, 0.2, 0.0]))\n",
    "print(\"H([1.0/3, 2.0/3]) = \", shannon([1.0/3, 2.0/3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Tracer, à l'aide de la fonction `plot`, la courbe donnant la valeur de `shannon([p, 1-p])` en fonction de `p`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour plot, on a besoin de la librairie suivante:\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Graphique des donnees\n",
    "P = []\n",
    "i = 0.0\n",
    "while i <= 1.0:\n",
    "    P.append(i)\n",
    "    i += 0.001\n",
    "    \n",
    "lst2 = []\n",
    "for p in P:\n",
    "    lst2.append(shannon([p, 1-p]))\n",
    "\n",
    "x = np.array(P)\n",
    "y = np.array(lst2)\n",
    "plt.xlabel(\"p\")\n",
    "plt.ylabel(\"shannon([p, 1-p]\")\n",
    "plt.plot(x, y)\n",
    "plt.show() # affiche la figure a l'ecran"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> A l'aide de la fonction <code>shannon</code>, écrire la fonction <code>entropie</code> qui prend un ensemble de labels en argument et renvoie l'entropie de la distribution des classes dans cet ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropie(Y):\n",
    "    \"\"\" Y : (array) : ensemble de labels de classe\n",
    "        rend l'entropie de l'ensemble Y\n",
    "    \"\"\"\n",
    "    \n",
    "    Etiq = []\n",
    "    dict_etiq = {}\n",
    "    for lab in Y:\n",
    "        if lab not in Etiq:\n",
    "            Etiq.append(lab)\n",
    "            dict_etiq[lab] = 1\n",
    "        else:\n",
    "            tmp = dict_etiq[lab]\n",
    "            tmp += 1\n",
    "            dict_etiq[lab] = tmp\n",
    "    \n",
    "    P = []\n",
    "    for etiq in dict_etiq.items():\n",
    "        P.append(etiq[1]/len(Y))\n",
    "    return shannon(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9544340029249649"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemple sur nos données :\n",
    "entropie(elections_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arbres de décision\n",
    "\n",
    "Dans cette partie, on réalise l'implémentation de l'algorithme de construction d'un arbre de décision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Représentation d'un arbre en Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "\n",
    "Pour représenter un arbre en Python, on a besoin de définir une structure de données adéquate. \n",
    "\n",
    "Un arbre de décision est défini par des **noeuds** qui sont de 2 types :\n",
    "- *noeud interne* : c'est un noeud qui est associé à un attribut (ie. une variable de description des exemples) et qui possède des fils qui sont aussi des noeuds. \n",
    "- *feuille* : c'est un noeud qui est associé à un label de la classe et qui a la particularité de ne pas avoir de descendants.\n",
    "\n",
    "Pour représenter des noeuds, nous définissons la classe `NoeudCategoriel` suivante:\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2118458485.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_14648/2118458485.py\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    import python-graphviz as gv\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# La librairie suivante est nécessaire pour l'affichage graphique de l'arbre:\n",
    "import graphviz as gv\n",
    "\n",
    "# Pour plus de détails : https://graphviz.readthedocs.io/en/stable/manual.html\n",
    "\n",
    "# Eventuellement, il peut être nécessaire d'installer graphviz sur votre compte:\n",
    "# pip install --user --install-option=\"--prefix=\" -U graphviz\n",
    "\n",
    "class NoeudCategoriel:\n",
    "    \"\"\" Classe pour représenter des noeuds d'un arbre de décision\n",
    "    \"\"\"\n",
    "    def __init__(self, num_att=-1, nom=''):\n",
    "        \"\"\" Constructeur: il prend en argument\n",
    "            - num_att (int) : le numéro de l'attribut auquel il se rapporte: de 0 à ...\n",
    "              si le noeud se rapporte à la classe, le numéro est -1, on n'a pas besoin\n",
    "              de le préciser\n",
    "            - nom (str) : une chaîne de caractères donnant le nom de l'attribut si\n",
    "              il est connu (sinon, on ne met rien et le nom sera donné de façon \n",
    "              générique: \"att_Numéro\")\n",
    "        \"\"\"\n",
    "        self.attribut = num_att    # numéro de l'attribut\n",
    "        if (nom == ''):            # son nom si connu\n",
    "            self.nom_attribut = 'att_'+str(num_att)\n",
    "        else:\n",
    "            self.nom_attribut = nom \n",
    "        self.Les_fils = None       # aucun fils à la création, ils seront ajoutés\n",
    "        self.classe   = None       # valeur de la classe si c'est une feuille\n",
    "        \n",
    "    def est_feuille(self):\n",
    "        \"\"\" rend True si l'arbre est une feuille \n",
    "            c'est une feuille s'il n'a aucun fils\n",
    "        \"\"\"\n",
    "        return self.Les_fils == None\n",
    "    \n",
    "    def ajoute_fils(self, valeur, Fils):\n",
    "        \"\"\" valeur : valeur de l'attribut de ce noeud qui doit être associée à Fils\n",
    "                     le type de cette valeur dépend de la base\n",
    "            Fils (NoeudCategoriel) : un nouveau fils pour ce noeud\n",
    "            Les fils sont stockés sous la forme d'un dictionnaire:\n",
    "            Dictionnaire {valeur_attribut : NoeudCategoriel}\n",
    "        \"\"\"\n",
    "        if self.Les_fils == None:\n",
    "            self.Les_fils = dict()\n",
    "        self.Les_fils[valeur] = Fils\n",
    "        # Rem: attention, on ne fait aucun contrôle, la nouvelle association peut\n",
    "        # écraser une association existante.\n",
    "    \n",
    "    def ajoute_feuille(self,classe):\n",
    "        \"\"\" classe: valeur de la classe\n",
    "            Ce noeud devient un noeud feuille\n",
    "        \"\"\"\n",
    "        self.classe    = classe\n",
    "        self.Les_fils  = None   # normalement, pas obligatoire ici, c'est pour être sûr\n",
    "        \n",
    "    def classifie(self, exemple):\n",
    "        \"\"\" exemple : numpy.array\n",
    "            rend la classe de l'exemple (pour nous, soit +1, soit -1 en général)\n",
    "            on rend la valeur 0 si l'exemple ne peut pas être classé (cf. les questions\n",
    "            posées en fin de ce notebook)\n",
    "        \"\"\"\n",
    "        if self.est_feuille():\n",
    "            return self.classe\n",
    "        if exemple[self.attribut] in self.Les_fils:\n",
    "            # descente récursive dans le noeud associé à la valeur de l'attribut\n",
    "            # pour cet exemple:\n",
    "            return self.Les_fils[exemple[self.attribut]].classifie(exemple)\n",
    "        else:\n",
    "            # Cas particulier : on ne trouve pas la valeur de l'exemple dans la liste des\n",
    "            # fils du noeud... Voir la fin de ce notebook pour essayer de résoudre ce mystère...\n",
    "            print('\\t*** Warning: attribut ',self.nom_attribut,' -> Valeur inconnue: ',exemple[self.attribut])\n",
    "            return 0\n",
    "    \n",
    "    def to_graph(self, g, prefixe='A'):\n",
    "        \"\"\" construit une représentation de l'arbre pour pouvoir l'afficher graphiquement\n",
    "            Cette fonction ne nous intéressera pas plus que ça, elle ne sera donc pas expliquée            \n",
    "        \"\"\"\n",
    "        if self.est_feuille():\n",
    "            g.node(prefixe,str(self.classe),shape='box')\n",
    "        else:\n",
    "            g.node(prefixe, self.nom_attribut)\n",
    "            i =0\n",
    "            for (valeur, sous_arbre) in self.Les_fils.items():\n",
    "                sous_arbre.to_graph(g,prefixe+str(i))\n",
    "                g.edge(prefixe,prefixe+str(i), valeur)\n",
    "                i = i+1        \n",
    "        return g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple d'utilisation: \n",
    "un_noeud0= NoeudCategoriel() \n",
    "un_noeud0.ajoute_feuille(-1)\n",
    "\n",
    "un_noeud1= NoeudCategoriel()\n",
    "un_noeud1.ajoute_feuille(+1)\n",
    "\n",
    "un_noeud2= NoeudCategoriel(0,\"nom2\")\n",
    "un_noeud2.ajoute_fils(\"val1\",un_noeud0)\n",
    "un_noeud2.ajoute_fils(\"val2\",un_noeud1)\n",
    "\n",
    "un_noeud3 = NoeudCategoriel(1,\"nom3\")\n",
    "un_noeud3.ajoute_fils(\"val3\",un_noeud2)\n",
    "\n",
    "# L'affichage se fait en 2 temps\n",
    "# 1) on initialise un graphe orienté :\n",
    "gtree = gv.Digraph(format='png')\n",
    "# 2) on le rempli en appelant la méthode de la classe NoeudCategoriel\n",
    "un_noeud3.to_graph(gtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "un_noeud3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction de l'arbre de décision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "Comme on l'a vu dans le cours, pour construire un arbre de décision à partir d'un dataset ($X$, $Y$), il faut réaliser les étapes suivantes:\n",
    "1. calculer l'entropie de Shannon de l'ensemble des classes $Y$, on la note $H_S(Y)$.\n",
    "2. si $H_S(Y)$ est inférieure à epsilon (qui est un réel positif donné en paramètre de l'algorithme), alors construire une feuille avec cet ensemble, la classe associée à cette feuille est la classe majoritaire dans $Y$.\n",
    "3. sinon, pour chaque attribut $X_j$ qui décrit les exemples de $X$,\n",
    "    - 3.1. pour chacune des valeurs $v_{jl}$ de $X_j$ construire l'ensemble des exemples de $X$ qui possède la valeur $v_{jl}$ ainsi que l'ensemble de leurs labels.\n",
    "    - 3.2. calculer l'entropie conditionnelle de Shannon de la classe relativement à l'attribut $X_j$. On note $H_S(Y|X_j)$ cette entropie.\n",
    "4. l'attribut $X_{best}$ qui **maximise le gain d'information** est choisi pour constituer un nouveau noeud $\\eta$ de l'arbre de décision:\n",
    "    - 4.1. chaque valeur de $X_{best}$ est utilisée pour décomposer ($X$, $Y$) en autant de datasets que $X_{best}$ possède de valeurs: chaque dataset est séparant $X$ et $Y$ selon la valeur prise pour $X_{best}$. \n",
    "    - 4.2. pour chaque dataset obtenu on reprend en 1 pour construire chacun des fils de $\\eta$. \n",
    "\n",
    "\n",
    "On rappelle que le gain d'information est:\n",
    "\n",
    "$$I_S(X_j,Y) = H_S(Y) - H_S(Y|X_j)$$\n",
    "\n",
    "On peut remarquer que chercher l'attribut $X_j$ qui **maximise le gain d'information** $I_S(X_j,Y)$ est équivalent à chercher $X_j$ qui **minimise l'entropie** $H_S(Y|X_j)$ (car le terme $H_S(Y)$ reste constant pour les calculs pour tous les attributs).\n",
    "   \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Compléter la fonction `construit_AD`suivante afin qu'elle permette de construire un arbre de décision. Cette fonction rend un `NoeudCategoriel` qui correspond à l'arbre construit pour le dataset $(X,Y)$ donné."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "\n",
    "def construit_AD(X,Y,epsilon,LNoms = []):\n",
    "    \"\"\" X,Y : dataset\n",
    "        epsilon : seuil d'entropie pour le critère d'arrêt \n",
    "        LNoms : liste des noms de features (colonnes) de description \n",
    "    \"\"\"\n",
    "    \n",
    "    # dimensions de X:\n",
    "    (nb_lig, nb_col) = X.shape\n",
    "    \n",
    "    entropie_classe = entropie(Y)\n",
    "    \n",
    "    if (entropie_classe <= epsilon) or  (nb_lig <=1):\n",
    "        # ARRET : on crée une feuille\n",
    "        noeud = NoeudCategoriel(-1,\"Label\")\n",
    "        noeud.ajoute_feuille(classe_majoritaire(Y))\n",
    "    else:\n",
    "        gain_max = sys.float_info.min  # meilleur gain trouvé (initalisé à -infinie)\n",
    "        i_best = -1         # numéro du meilleur attribut\n",
    "        Xbest_valeurs = None\n",
    "        \n",
    "        #############\n",
    "        \n",
    "        # COMPLETER CETTE PARTIE : ELLE DOIT PERMETTRE D'OBTENIR DANS\n",
    "        # i_best : le numéro de l'attribut qui maximise le gain d'information.  En cas d'égalité,\n",
    "        #          le premier rencontré est choisi.\n",
    "        # gain_max : la plus grande valeur de gain d'information trouvée.\n",
    "        # Xbest_valeurs : la liste des valeurs que peut prendre l'attribut i_best\n",
    "        #\n",
    "        # Il est donc nécessaire ici de parcourir tous les attributs et de calculer\n",
    "        # la valeur du gain d'information pour chaque attribut.\n",
    "        \n",
    "        tabHS = []\n",
    "        # pour chaque attribut  𝑋𝑗  qui décrit les exemples de  𝑋 \n",
    "        for i in range(len(LNoms)):\n",
    "            Xj = LNoms[i]\n",
    "            \n",
    "            # pour chacune des valeurs 𝑣𝑗𝑙 de 𝑋𝑗\n",
    "            valeurs_vjl = []\n",
    "            dict_valeurs_vjl = {}\n",
    "            for exemp in X:\n",
    "                if exemp[i] not in valeurs_vjl:\n",
    "                    valeurs_vjl.append(exemp[i])\n",
    "                    # construire l'ensemble des exemples de  𝑋  qui possède la valeur  𝑣𝑗𝑙  \n",
    "                    # ainsi que l'ensemble de leurs labels\n",
    "                    vjl = exemp[i]\n",
    "                    exemples_X = []\n",
    "                    leurs_labels = []\n",
    "                    for j in range(len(X)):\n",
    "                        ex = X[j]\n",
    "                        if vjl in ex:\n",
    "                            exemples_X.append(ex)\n",
    "                            leurs_labels.append(Y[j])\n",
    "                    dict_valeurs_vjl[vjl] = [exemples_X, leurs_labels]\n",
    "            \n",
    "            # calculer l'entropie conditionnelle de Shannon de la classe relativement à l'attribut  𝑋𝑗 . \n",
    "            # On note  𝐻𝑆(𝑌|𝑋𝑗)  cette entropie.\n",
    "            HSy_xj = 0\n",
    "            for vjl in valeurs_vjl:\n",
    "                #nbocc = nbr de ligne il a apparait\n",
    "                entro_vjl = entropie(dict_valeurs_vjl[vjl][1]) * (len(dict_valeurs_vjl[vjl][0])/len(Y))\n",
    "                HSy_xj = HSy_xj + entro_vjl\n",
    "            tabHS.append(HSy_xj)\n",
    "        \n",
    "        i_best = tabHS.index(min(tabHS))\n",
    "        gain_max = tabHS[i_best]\n",
    "        Xbest_valeurs = np.unique(X[:, i_best])\n",
    "            \n",
    "        if len(LNoms)>0:  # si on a des noms de features\n",
    "            noeud = NoeudCategoriel(i_best,LNoms[i_best])    \n",
    "        else:\n",
    "            noeud = NoeudCategoriel(i_best)\n",
    "        for v in Xbest_valeurs:\n",
    "            noeud.ajoute_fils(v,construit_AD(X[X[:,i_best]==v], Y[X[:,i_best]==v],epsilon,LNoms))\n",
    "    return noeud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La classe pour implémenter un arbre de décision dérive de la classe `Classifier`. Elle utilise la fonction `construit_AD` dans sa méthode `train` pour construire un arbre à partir d'un dataset donné.\n",
    "\n",
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Compléter la classe suivante en donnant le code des méthodes `train` et `predict`.\n",
    "\n",
    "**Remarque :** la méthode `score` ne fera rien dans notre cas, on verra dans un autre notebook comment on pourrait la définir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierArbreDecision(cl.Classifier):\n",
    "    \"\"\" Classe pour représenter un classifieur par arbre de décision\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_dimension, epsilon, LNoms=[]):\n",
    "        \"\"\" Constructeur\n",
    "            Argument:\n",
    "                - intput_dimension (int) : dimension de la description des exemples\n",
    "                - epsilon (float) : paramètre de l'algorithme (cf. explications précédentes)\n",
    "                - LNoms : Liste des noms de dimensions (si connues)\n",
    "            Hypothèse : input_dimension > 0\n",
    "        \"\"\"\n",
    "        self.dimension = input_dimension\n",
    "        self.epsilon = epsilon\n",
    "        self.LNoms = LNoms\n",
    "        # l'arbre est manipulé par sa racine qui sera un Noeud\n",
    "        self.racine = None\n",
    "        \n",
    "    def toString(self):\n",
    "        \"\"\"  -> str\n",
    "            rend le nom du classifieur avec ses paramètres\n",
    "        \"\"\"\n",
    "        return 'ClassifierArbreDecision ['+str(self.dimension) + '] eps='+str(self.epsilon)\n",
    "        \n",
    "    def train(self, desc_set, label_set):\n",
    "        \"\"\" Permet d'entrainer le modele sur l'ensemble donné\n",
    "            desc_set: ndarray avec des descriptions\n",
    "            label_set: ndarray avec les labels correspondants\n",
    "            Hypothèse: desc_set et label_set ont le même nombre de lignes\n",
    "        \"\"\"        \n",
    "        self.racine = construit_AD(desc_set, label_set, self.epsilon, self.LNoms)\n",
    "    \n",
    "    def score(self,x):\n",
    "        \"\"\" rend le score de prédiction sur x (valeur réelle)\n",
    "            x: une description\n",
    "        \"\"\"\n",
    "        # cette méthode ne fait rien dans notre implémentation :\n",
    "        pass\n",
    "    \n",
    "    def predict(self, x):\n",
    "        \"\"\" x (array): une description d'exemple\n",
    "            rend la prediction sur x             \n",
    "        \"\"\"\n",
    "        ##################\n",
    "        ## COMPLETER ICI !\n",
    "        ##################\n",
    "        return self.racine.classifie(x)\n",
    "\n",
    "    def accuracy(self, desc_set, label_set):  # Version propre à aux arbres\n",
    "        \"\"\" Permet de calculer la qualité du système sur un dataset donné\n",
    "            desc_set: ndarray avec des descriptions\n",
    "            label_set: ndarray avec les labels correspondants\n",
    "            Hypothèse: desc_set et label_set ont le même nombre de lignes\n",
    "        \"\"\"\n",
    "        nb_ok=0\n",
    "        for i in range(desc_set.shape[0]):\n",
    "            if self.predict(desc_set[i,:]) == label_set[i]:\n",
    "                nb_ok=nb_ok+1\n",
    "        acc=nb_ok/(desc_set.shape[0] * 1.0)\n",
    "        return acc\n",
    "\n",
    "    def affiche(self,GTree):\n",
    "        \"\"\" affichage de l'arbre sous forme graphique\n",
    "            Cette fonction modifie GTree par effet de bord\n",
    "        \"\"\"\n",
    "        self.racine.to_graph(GTree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Premières expérimentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apprentissage d'un arbre de décision avec la base sur les élections :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiation d'un arbre pour le dataset Elections:\n",
    "arbre_elections = ClassifierArbreDecision(len(elections_noms), 0.0, elections_noms)\n",
    "\n",
    "# Construction de l'arbre de décision à partir du dataset Elections\n",
    "arbre_elections.train(elections_desc,elections_label)\n",
    "\n",
    "# Construction de la représentation graphique (affichage)\n",
    "graphe_arbre_elections = gv.Digraph(format='png')\n",
    "arbre_elections.affiche(graphe_arbre_elections)\n",
    "\n",
    "# Affichage du graphe obtenu:\n",
    "graphe_arbre_elections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour classer un nouvel exemple avec un arbre de décision, on utilise la méthode <code>predict</code> qui utilise la méthode `classifie` de la classe `NoeudCategoriel` pour classer un nouvel exemple et renvoyer le label +1 ou -1 selon le cas. \n",
    "\n",
    "Exemple de classification d'un exemple avec l'arbre obtenu :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbre_elections.predict(elections_desc[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification d'un nouvel exemple qui n'appartient à pas au dataset d'apprentissage :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rappel : elections_noms = ['Adresse', 'Majeur?', 'Nationalite']\n",
    "arbre_elections.predict(np.array(['Paris','oui','Italien']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mesure de l'accuracy de l'arbre obtenu :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbre_elections.accuracy(elections_desc,elections_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Première expérimentation avec la base Mushrooms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour mieux évaluer notre nouvel algortithme d'apprentissage, on va utiliser la base des champignons `mushrooms-1000.csv` qui est fournie dans le répertoire `data`. Ce dataset est une version réduite du dataset original qui comporte plus de 8000 champignons.\n",
    "\n",
    "\n",
    "\n",
    "Dans le répertorie `data/` fourni avec ce sujet, vous pouvez trouver 6 fichiers `mushrooms-****.csv`. Ces 6 fichiers ont été obtenus en partitionant le fichier orignal `mushrooms.csv` que l'on peut trouver sur internet. Dans cette base originale, il y a 8124 champignons recensés. Ce fichier original a été découpé en 5 fichiers de 1400 champignons et 1 fichier de 1124 champignons. L'union de ces 6 fichiers permet donc de recomposer le fichier original.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction d'un arbre de décision\n",
    "\n",
    "Dans un premier temps, on vérifie que notre algorithme d'apprentissage fonctionne correctement en construisant un arbre de décision à partir d'un des fichiers.\n",
    "\n",
    "On commence par charger le fichier dans un dataframe et on le transforme en dataset (cf. le notebook précédent pour le détail des étapes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des fichiers de données sur les mushrooms:\n",
    "\n",
    "# On commence par travailler sur un des fichier \"mushrooms-1400\"\n",
    "mushrooms_df = pd.read_csv(\"data/mushrooms-1400-1.csv\")\n",
    "\n",
    "mushrooms_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noms des colonnes:\n",
    "# Dans ce dataframe, la colonne de classe s'appelle 'class'\n",
    "mushrooms_noms = [nom for nom in mushrooms_df.columns if nom != 'class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passer du dataframe à un dataset (2 arrays):\n",
    "mushrooms_1_desc = np.array(mushrooms_df[mushrooms_noms])\n",
    "mushrooms_1_label = np.array(mushrooms_df['class'])\n",
    "mushrooms_1_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, on construit l'arbre de décision correspondant.\n",
    "\n",
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Compléter le code suivant pour apprendre l'arbre et l'afficher ensuite:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construction de l'arbre de décision à partir du dataset Elections:\n",
    "arbre_mushrooms_1 = ClassifierArbreDecision(len(mushrooms_noms), 0.0, mushrooms_noms)\n",
    "arbre_mushrooms_1.train(mushrooms_1_desc, mushrooms_1_label)\n",
    "\n",
    "# Affichage du graphe obtenu:\n",
    "gr_arbre_mushrooms_1 = gv.Digraph(format='png')\n",
    "arbre_mushrooms_1.affiche(gr_arbre_mushrooms_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr_arbre_mushrooms_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification avec l'arbre de décision obtenu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemple de classification d'un exemple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbre_mushrooms_1.predict(mushrooms_1_desc[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcul de l'accuracy sur le dataset d'apprentissage :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbre_mushrooms_1.accuracy(mushrooms_1_desc,mushrooms_1_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Toujours avec le dataset `mushrooms_1` précédent, construire un nouvel arbre de décision en utilisant comme valeur d'epsilon : $0.25$.\n",
    "\n",
    "Que constatez-vous ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "\n",
    "# A COMPLETER \n",
    "\n",
    "#################################\n",
    "\n",
    "\n",
    "#################################\n",
    "# Affichage du graphe obtenu:\n",
    "gr_arbre_mushrooms_1_bis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Résultat attendu :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Déterminer l'accuracy de ce nouvel arbre.\n",
    "\n",
    "**Attention**: votre fonction `predict` doit pouvoir tenir compte du fait que les classes ne sont pas égales à +1 ou -1..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbre_mushrooms_1_bis.accuracy(mushrooms_1_desc,mushrooms_1_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> D'après ces résultats, de ces 2 arbres, quel est celui qui a sur-appris ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour expérimenter un classifieur, on a vu qu'il est nécessaire de posséder deux datasets distincts: \n",
    "- le dataset d'apprentissage, qui se compose donc de 2 arrays: `train_desc` et `train_labels`\n",
    "- et le dataset de test, qui se compose de 2 arrays: `test_desc` et `test_labels`. \n",
    "\n",
    "\n",
    "On commence par construire le classifieur avec le dataset d'apprentisage, puis, on évalue sa performance en 2 temps :\n",
    "- on calcule son **accuracy d'apprentissage** qui est l'accuracy obtenue sur le dataset d'apprentissage \n",
    "- on calcule son **accuracy de test** qui est l'accuracy obtenue sur le dataset de test\n",
    "\n",
    "La première valeur mesure combien le classifieur a appris les données d'apprentissage, la deuxième valeur mesure sa performance en généralisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plus d'expérimentations avec la base Mushrooms\n",
    "\n",
    "On décide maintenant d'évaluer plus en détail ce nouvel algorithme. On souhaite:\n",
    "1. construire un arbre avec chaque fichier `mushrooms-1400-*.csv` \n",
    "2. pour chaque arbre construit, évaluer son accuracy:\n",
    "    - sur le dataset d'apprentissage\n",
    "    - sur les 4 autres fichiers `mushrooms-1400-*.csv`\n",
    "    - sur le fichier `mushrooms-1124.csv`\n",
    "    \n",
    "    \n",
    "**Remarque :** normalement, tous ces tests devraient pouvoir se faire dans un temps raisonnable, dans le cas contraire, faites les un par un."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des fichiers mushrooms et apprentissage\n",
    "mushrooms_desc = []\n",
    "mushrooms_label = []\n",
    "arbres_mushrooms = []\n",
    "for j in range(0,5):\n",
    "    mushrooms_df = pd.read_csv(\"data/mushrooms-1400-\"+str(j+1)+\".csv\")\n",
    "    mushrooms_noms = [nom for nom in mushrooms_df.columns if nom != 'class']\n",
    "    # Passer du dataframe à un dataset (2 arrays):\n",
    "    mushrooms_desc.append(np.array(mushrooms_df[mushrooms_noms]))\n",
    "    mushrooms_label.append(np.array(mushrooms_df['class']))\n",
    "    \n",
    "    # Apprentissage\n",
    "    arbres_mushrooms.append(ClassifierArbreDecision(len(mushrooms_noms), 0.0, mushrooms_noms))\n",
    "    arbres_mushrooms[j].train(mushrooms_desc[j],mushrooms_label[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fichier qui va nous servir à tester\n",
    "mushrooms_df = pd.read_csv(\"data/mushrooms-1124.csv\")\n",
    "\n",
    "# Passer du dataframe à un dataset (2 arrays):\n",
    "mushrooms_test_desc = np.array(mushrooms_df[mushrooms_noms])\n",
    "mushrooms_test_label = np.array(mushrooms_df['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Donner les instructions permettant d'obtenir le taux de bonne classification (accuracy) de chacun des arbres construits sur les autres bases, sur le modèle suivant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> On peut remarquer que pour certains arbres, la classification de certains exemples produit un warning.\n",
    "En étudiant les exemples suivant et leur classification par le premier arbre, expliquez pourquoi un warning se produit.\n",
    "Est-ce normal ? Pourrait-on trouver une solution pour ces cas-là ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,1400):\n",
    "    prediction = arbres_mushrooms[0].predict(mushrooms_desc[3][i,:])\n",
    "    if prediction == 0:\n",
    "        print(i,\" --> pas de prédiction, le label rendu est \",prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Regrouper les 6 fichiers mushrooms et réaliser une évaluation de l'algorithme de construction d'arbres en utilisant votre fonction `crossvalidation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation \"Leave one out\"\n",
    "\n",
    "Nous avons vu 2 approches pour évaluer un algorithme d'apprentissage:\n",
    "- la mesure de l'accuracy sur les données d'apprentissage et sur une base de test\n",
    "- la réalisation d'une validation croisée pour mesurer l'accuracy et l'écart type (pour évaluer la robustesse) mesurées sur les données utilisées pour apprendre le modèle (données d'apprentissage) et sur des données qui n'ont pas été utilisées pour mettre au point le modèle (données test)\n",
    "\n",
    "La première approche est généralement utilisée pour comparer plusieurs modèles en regardant leur accuracy sur les mêmes données de test.\n",
    "La deuxième approche est, elle, utilisée pour aussi obtenir une certaine évaluation de la robustesse du modèle appris et garantir que l'accuracy mesurée n'est pas simplement obtenue sur \"un cas particulier\" de données.\n",
    "\n",
    "Cependant, il existe des cas où le dataset que l'on possède ne contient pas beaucoup d'exemples. Dans ce cas, deux possibilités:\n",
    "- il y a suffisament de données dans le dataset pour réaliser une validation croisée en réduisant le nombre de paquets (ie. prendre 4 paquets au lieu de 10 par exemple);\n",
    "- il y a trop peu d'exemples pour qu'une validation croisée soit réalisable, on utilise alors une autre technique d'évaluation: l'évaluation par **leave one out** (littéralement: \"en mettre un de côté\"). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'évaluation par **leave one out** procède ainsi: à partir d'un dataset $DS$ contenant $n$ exemples:\n",
    "1. sortir un des exemples de $DS$ et le mettre de côté\n",
    "2. apprendre le modèle sur les $n-1$ exemples non sortis de $DS$\n",
    "3. tester le modèle appris sur l'exemple mis de côté: il est soit bien classé (on marque 1 pt), soit mal classé (on marque 0 pt)\n",
    "4. prendre le $DS$ original est choisir un exemple différent à mettre de côté\n",
    "5. reprendre en 1) \n",
    "\n",
    "Les étapes 4) et 5) sont faites jusqu'à ce que tous les exemples de $DS$ aient été sortis à leur tour de $DS$.\n",
    "A la fin, l'accuracy de test du modèle est alors donnée par le ratio $\\frac{\\mbox{nombre de points marqués}}{n}$.\n",
    "\n",
    "<i>Remarque</i>: le plus simple dans cette approche, c'est de sortir les exemples en les prenant dans l'ordre dans lequel ils sont dans le dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Ecrire la fonction `leave_one_out` qui prend en argument un algorithme d'apprentissage $C$ et un dataset $DS$ et rend l'accuracy de test de $C$ calculée sur $DS$ en utilisant l'évaluation par leave one out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy  # pour utiliser copy.deepcopy() qui permet de faire des copies de C \n",
    "\n",
    "# ------------------------ A COMPLETER :\n",
    "def leave_one_out(C, DS):\n",
    "    \"\"\" Classifieur * tuple[array, array] -> float\n",
    "    \"\"\"\n",
    "    \n",
    "    raise NotImplementedError(\"Please Implement this method\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tester avec la base sur les élections européennes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement et préparation du dataset:\n",
    "elections_df = pd.read_csv(\"data/elections.csv\")\n",
    "elections_noms = [nom for nom in elections_df.columns if nom != 'Label']\n",
    "\n",
    "data_desc = np.array(elections_df[elections_noms])\n",
    "data_label = np.array(elections_df['Label'])\n",
    "\n",
    "# Lancement du leave one out\n",
    "leave_one_out(ClassifierArbreDecision(len(elections_noms), 0.1, elections_noms),(data_desc,data_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison avec d'autres algorithmes\n",
    "\n",
    "Afin de pouvoir comparer les autres classifieurs que l'on a vu précédemment avec celui par arbres de décision, il faut les adapter afin qu'ils puissent traiter les données catégorielles.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Travailler avec des données catégorielles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le cours 6, nous avons vu comment adapter des données catégorielles en données numériques, à l'aide d'un encodage one-hot. Afin de pouvoir utiliser les classifieurs (numériques) que nous avons déjà implémentés nous utiliserons cet encodage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Transformer les données \"élections\" pour créer un dataset essentiellement numérique. Pour cela, appliquer le one-hot encoding sur les attributs catégoriels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Appliquer divers classifieurs écrits dans les TME précédent sur cette base ainsi catégorisée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Adapter la transformation précédente pour réaliser un ensemble d'expérimentations sur la base mushrooms permettant de comparer les résultats obtenus avec un classifieur par arbres de décision et les classifieurs numériques que l'on a définis dans les séances précédentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
